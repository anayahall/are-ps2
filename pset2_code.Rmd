---
title: 'Problem Set #2'
author: "Anaya Hall & Christian Miller"
output: pdf_document
fontsize: 11pt
geometry: margin=.75in 
---

# Part 1: Theory
(for practice only)

# Part 2: Applied - Returns to Scale in Electricity Supply

```{r Setup, include=F}
rm(list = ls())
# Setup
knitr::opts_chunk$set(echo = T, cache = T)
# Options
options(stringsAsFactors = F)
# Packages
library(pacman)
p_load(knitr, kableExtra, WDI, dplyr, readr, magrittr, ggplot2, readxl, ascii)

# GGplot2 theme----
theme_are <- theme(
  legend.position = "bottom",
  panel.background = element_rect(fill = NA),
  panel.border = element_rect(fill = NA, color = "grey75"),
  axis.ticks = element_line(color = "grey85"),
  panel.grid.major = element_line(color = "grey95", size = 0.2),
  panel.grid.minor = element_line(color = "grey95", size = 0.2),
  legend.key = element_blank()
)

```


First, load our OLS function created in Problem Set #1. We're including a built in t-test this time around.

```{r OLS function}
ols <- function(data, y_data, X_data, intercept = T, H0 = 0, two_tail = T, alpha = 0.05) {
  # Function setup ----
    # Require the 'dplyr' package
    require(dplyr)
    # Function to convert tibble, data.frame, or tbl_df to matrix
    to_matrix <- function(the_df, vars) {
      # Create a matrix from variables in var
      new_mat <- the_df %>%
        #Select the columns given in 'vars'
        select_(.dots = vars) %>%
        # Convert to matrix
        as.matrix()
      # Return 'new_mat'
      return(new_mat)
    }
  
  # Create dependent and independent variable matrices ----
    # y matrix
    y <- to_matrix (the_df = data, vars = y_data)
    # X matrix
    X <- to_matrix (the_df = data, vars = X_data)
      # If 'intercept' is TRUE, then add a column of ones
      if (intercept == T) {
      X <- cbind(1,X)
      colnames(X) <- c("intercept", X_data)
      }
 
  # Calculate b, y_hat, and residuals ----
    b <- solve(t(X) %*% X) %*% t(X) %*% y
    y_hat <- X %*% b
    e <- y - y_hat
  
  # Useful -----
    n <- nrow(X) # number of observations
    k <- ncol(X) # number of independent variables
    dof <- n - k # degrees of freedom
    i <- rep(1,n) # column of ones for demeaning matrix
    A <- diag(i) - (1 / n) * i %*% t(i) # demeaning matrix
    y_star <- A %*% y # for SST
    X_star <- A %*% X # for SSM
    SST <- drop(t(y_star) %*% y_star)
    SSM <- drop(t(b) %*% t(X_star) %*% X_star %*% b)
    SSR <- drop(t(e) %*% e)
  
  # Measures of fit and estimated variance ----
    R2uc <- drop((t(y_hat) %*% y_hat)/(t(y) %*% y)) # Uncentered R^2
    R2 <- 1 - SSR/SST # Uncentered R^2
    R2adj <- 1 - (n-1)/dof * (1 - R2) # Adjusted R^2
    AIC <- log(SSR/n) + 2*k/n # AIC
    SIC <- log(SSR/n) + k/n*log(n) # SIC
    s2 <- SSR/dof # s^2
  
  # Measures of fit table ----
    mof_table_df <- data.frame(R2uc, R2, R2adj, SIC, AIC, SSR, s2)
    mof_table_col_names <- c("$R^2_\\text{uc}$", "$R^2$",
                             "$R^2_\\text{adj}$",
                             "SIC", "AIC", "SSR", "$s^2$")
    mof_table <-  mof_table_df %>% knitr::kable(
      row.names = F,
      col.names = mof_table_col_names,
      format.args = list(scientific = F, digits = 4),
      booktabs = T,
      escape = F
    )
  
  # t-test----
    # Standard error
    se <- as.vector(sqrt(s2 * diag(solve(t(X) %*% X))))
    # Vector of _t_ statistics
    t_stats <- (b - H0) / se
    # Calculate the p-values
    if (two_tail == T) {
    p_values <- pt(q = abs(t_stats), df = dof, lower.tail = F) * 2
    } else {
      p_values <- pt(q = abs(t_stats), df = dof, lower.tail = F)
    }
    # Do we (fail to) reject?
    reject <- ifelse(p_values < alpha, reject <- "Reject", reject <- "Fail to Reject")
    
    # Nice table (data.frame) of results
    ttest_df <- data.frame(
      # The rows have the coef. names
      effect = rownames(b),
      # Estimated coefficients
      coef = as.vector(b) %>% round(3),
      # Standard errors
      std_error = as.vector(se) %>% round(3),
      # t statistics
      t_stat = as.vector(t_stats) %>% round(3),
      # p-values
      p_value = as.vector(p_values) %>% round(4),
      # reject null?
      significance = as.character(reject)
      )
  
    ttest_table <-  ttest_df %>% knitr::kable(
      booktabs = T,
      format.args = list(scientific = F),
      escape = F
    )

  # Data frame for exporting for y, y_hat, X, and e vectors ----
    export_df <- data.frame(y, y_hat, e, X) %>% tbl_df()
    colnames(export_df) <- c("y","y_hat","e",colnames(X))
  
  # Return ----
    return(list(n=n, dof=dof, b=b, vars=export_df, R2uc=R2uc,R2=R2,
                R2adj=R2adj, AIC=AIC, SIC=SIC, s2=s2, SST=SST, SSR=SSR,
                mof_table=mof_table, ttest=ttest_table))
}
```

We'll also need a function to do an F-test for this Problem Set.

```{r F-test function}

to_matrix <- function(the_df, vars) {
      # Create a matrix from variables in var
      new_mat <- the_df %>%
        #Select the columns given in 'vars'
        select_(.dots = vars) %>%
        # Convert to matrix
        as.matrix()
      # Return 'new_mat'
      return(new_mat)
    }


# Joint test function (from Ed's notes). Could also write a more complex functions that takes R and r. 
F_test <- function(data, y_var, X_vars) {
  # Turn data into matrices
  y <- to_matrix(data, y_var)
  X <- to_matrix(data, X_vars)
  # Add intercept
  X <- cbind(1, X)
  # Name the new column "intercept"
  colnames(X) <- c("intercept", X_vars)
  # Calculate n and k for degrees of freedom
  n <- nrow(X)
  k <- ncol(X)
  # J is k-1
  J <- k - 1
  # Create the R matrix: bind a column of zeros
  # onto a J-by-J identity matrix
  R <- cbind(0, diag(J))

  # Estimate coefficients
  b <- ols(data, y_var, X_vars)
  # Retrieve OLS residuals
  e <- b$vars$e
  # Retrieve s^2
  s2 <- b$s2 %<>% as.numeric()

  # Create the inner matrix R(X'X)^(-1)R'
  RXXR <- R %*% solve(t(X) %*% X) %*% t(R)
  # Calculate the F stat
  f_stat <- t(R %*% b$b) %*% solve(RXXR) %*% (R %*% b$b) / J / s2
  # Calculate the p-value;; why normal and not chi^2
  p_value <- pf(q = f_stat, df1 = J, df2 = n-k, lower.tail = F)
  # Create a data.frame of the f stat. and p-value
  results <- data.frame(
    f_stat = f_stat %>% as.vector(),
    p_value = p_value %>% as.vector())
  return(results)
  
}

```


## Question 1:
**Read the data into R. Inspect it. Sort by size (Q (kwh)).** 


```{r read_in_data}

nerlove <- readxl::read_excel("nerlove.xls", col_names=T)
summary(nerlove)

# Fix typo in 13th row (missing a decimal!)
# DO THIS MORE ELEGANTLY! 
nerlove[13, "PL"] <- 1.81

# nerlove %>% 
#   filter(PL > 100) %>%
#     mutate(PL = PL/100)

nerlove %>% arrange(Q)

```

Plot the series and make sure your data are read in correctly. 
```{r plotseries, highlight=T}
ggplot(nerlove, aes(x=Q, y=TC)) + 
  geom_point() + 
  labs(title="Nerlove Data", x="Output (kWh)", y="Total Cost")

ggplot(nerlove, aes(x=PL, y=TC)) + 
  geom_point() + 
  labs(title="Nerlove Data", x="Price of Labor ($)", y="Total Cost")

ggplot(nerlove, aes(x=PK, y=TC)) + 
  geom_point() + 
  labs(title="Nerlove Data", x="Price of Capital ($)", y="Total Cost")

ggplot(nerlove, aes(x=PF, y=TC)) + 
  geom_point() + 
  labs(title="Nerlove Data", x="Price of Fuel ($)", y="Total Cost")

```

## Question 2:
**Replicate regression I (page 176) in the paper.**

Regression I:

$log(TC) - log(P_F) = \beta_0 + \beta_1Q + \beta_2\Bigl(log(P_L)-log(P_F)\Bigr) + \beta_3\Bigl(log(P_K)-log(P_F)\Bigr)$

Equivalent to:

$log(\frac{TC}{P_F}) = \beta_0 + \beta_1Q + \beta_2log(\frac{P_L}{P_F}) + \beta_3log(\frac{P_K}{P_F})$


Where:  
$TC$ = total production cost,

$P_L$ = wage rate,

$P_K$ = "price" of capital, 

$P_F$ = price of fuel,

$Q$ = output (measured in kWh)  



In generalized Cobb-Douglas form:

$\beta_1 = \frac{1}{r}$, 

$\beta_2 = \frac{a_L}{r}$, 

$\beta_3 = \frac{a_K}{r}$

Prepare variables for Regression I.
```{r RegressionI_prep}
# Create log variables
nerlove %<>% mutate(
  TClog = log(TC),
  Qlog = log(Q),
  PLlog = log(PL),
  PKlog = log(PK),
  PFlog = log(PF)
)

# Create PF scaled variables
nerlove %<>% mutate(
  TCscaled = TClog - PFlog,
  PLscaled = PLlog - PFlog,
  PKscaled = PKlog - PFlog
)
```

Variable names:

$log(\frac{TC}{P_F})$ = "TCscaled"

$log(\frac{P_L}{P_F})$ = "PLscaled"

$log(\frac{P_K}{P_F})$ = "PKscaled"

```{r RegressionI}

# Regression I: 
# dep var = (log costs - log fuel price) = TCscaled
reg_I <- ols(data = nerlove,y_data = "TCscaled",
             X_data = c("Qlog","PLscaled","PKscaled"),
             intercept = T, H0 = 0, alpha = 0.05)

reg_I$ttest
reg_I$mof_table

```

*Coefficients are pretty close to those in the paper. $R^2$ matches!*


## Question 3:
**Conduct the hypothesis test using constant returns to scale ($\beta_1$ = 1) as your null hypothesis.**

```{r null1}

# Re-run regression with null hypothesis H0 = 1
reg_I <- ols(data = nerlove, y_data = "TCscaled",
             X_data = c("Qlog","PLscaled","PKscaled"),
             intercept = T, H0 = 1, alpha = 0.05)

reg_I$ttest
```


**What is the p- value associated with you test statistic? What is your point estimate of returns to scale? Constant? Increasing? Decreasing?**

*The p-value is 0.000. The point estimate of returns to scale is $\frac{1}{\beta}=r =$ `r 1/reg_I$b[2]`, hence returns to scale is increasing.*

## Question 4:
**Plot residuals against output.**

```{r plotresid}

ggplot(reg_I$vars, aes(y=e, x=Qlog)) + geom_point() + labs(title="Regression I: Residuals against Output", x="Output (log(Q))", y="Residuals")

```

**What do you notice? What does this potentially tell you from an economic perspective?**

*Evidence of heteroskedasticity: residuals seem to track the log output through parabola. We may want to rethink our specification!*



**Compute the correlation coefficient of the residuals with output for the entire sample? What does this tell you?**

```{r corr coeff}
# R = cov(xy)/var(x)var(y)
R_I <- (cov(x=reg_I$vars$e, y=reg_I$vars$Qlog)/(var(reg_I$vars$e)*var(reg_I$vars$Qlog))) %>% signif(3) %>% as.character()
```
The correlation coefficient is extremely small: `r R_I`. This tells us that, conversely, there is very little correlation between the output of the firm and the undetermined part of the model. This supports our strict exogeneity assumption.

## Question 5:
**Divide your sample into 5 subgroups of 29 firms each according to the level of output. Estimate the regression model again for each group separately.**

```{r split_sample}
# Divide sample into 5 subgroups
d <- split(nerlove,rep(1:5,each=29))

# Now we have a list, d, with five dataframes '1' through '5' for our five subgroups.
```

```{r Regression III}
# Regression IIIA
reg_IIIA <- ols(data = d$`1`,y_data = "TCscaled",
             X_data = c("Qlog","PLscaled","PKscaled"),
             intercept = T, H0 = 1, alpha = 0.05)
reg_IIIA$ttest

# Regression IIIB
reg_IIIB <- ols(data = d$`2`,y_data = "TCscaled",
             X_data = c("Qlog","PLscaled","PKscaled"),
             intercept = T, H0 = 1, alpha = 0.05)
reg_IIIB$ttest

# Regression IIIC
reg_IIIC <- ols(data = d$`3`,y_data = "TCscaled",
             X_data = c("Qlog","PLscaled","PKscaled"),
             intercept = T, H0 = 1, alpha = 0.05)
reg_IIIC$ttest

# Regression IIID
reg_IIID <- ols(data = d$`4`,y_data = "TCscaled",
             X_data = c("Qlog","PLscaled","PKscaled"),
             intercept = T, H0 = 1, alpha = 0.05)
reg_IIID$ttest

# Regression IIIE
reg_IIIE <- ols(data = d$`5`,y_data = "TCscaled",
             X_data = c("Qlog","PLscaled","PKscaled"),
             intercept = T, H0 = 1, alpha = 0.05)
reg_IIIE$ttest
```

**Can you replicate Equations IIIA - IIIE? Calculate the point estimates for returns to scale for each sample. Is there a pattern relating to size of output?**

```{r Regression III rts}
# Create Returns to scale table
rts <- rbind(1/reg_IIIA$b[2], 1/reg_IIIB$b[2], 1/reg_IIIC$b[2], 
             1/reg_IIID$b[2], 1/reg_IIIE$b[2])
rts_rownames <- rbind("IIIA", "IIIB","IIIC","IIID","IIIE")

reg_III_df <- data.frame(rts_rownames,rts)


reg_III_table <- reg_III_df %>% knitr::kable(
    col.names = c("Regression","Returns to Scale"),
    format.args = list(scientific = F, digits = 4),
    booktabs = T,
    escape = F
  )

reg_III_table
```

*Coefficients roughly match the results of the paper! As the size (output) of the firms get larger they see decreasing, increasing returns to scale. The largest bucket even sees decreasing returns to scale.*


## Question 6: 
**Create ”dummy variables” for each industry. Interact them with the output variable to create five ”slope coefficients”.**

``` {r createdummies}

# create group categorical var
for (i in 1:5) {
  d[[i]] %<>% mutate(gvar=i)
}

# unsplit
df <- rbind(d[[1]], d[[2]], d[[3]], d[[4]], d[[5]])

# create dummies
df %<>%
    mutate(
      g1 = ifelse(gvar==1, 1, 0),
      g2 = ifelse(gvar==2, 1, 0),
      g3 = ifelse(gvar==3, 1, 0),
      g4 = ifelse(gvar==4, 1, 0),
      g5 = ifelse(gvar==5, 1, 0)) %>% select(-gvar)
  

# interact with output variable
df %<>%
    mutate(
      lQ_A = Qlog*g1,
      lQ_B = Qlog*g2,
      lQ_C = Qlog*g3,
      lQ_D = Qlog*g4,
      lQ_E = Qlog*g5)

```

**Run a model, letting the intercept and slope coefficient on output differ across plants, but let the remainder of the coefficients be pooled across plants.**

```{r OLS_dummies}

# I'm not sure this is the right model... but I'm gettin similar coeffs!
# I think this is correct my friend


reg_IV <- ols(data = df, y_data = "TCscaled",
             X_data = c("lQ_A", "lQ_B", "lQ_C", "lQ_D", "lQ_E", 
                        "PLscaled", "PKscaled", "g1", "g2", "g3", "g4", "g5"), 
             intercept = F, H0 = 0, alpha = 0.05)

# Can also omit one of the dummie vars (g) and include an intercept >> get the same coefs
reg_IV$ttest

reg_IV$mof_table

# Create Returns to scale table
rts <- rbind(1/reg_IV$b[1], 1/reg_IV$b[2], 1/reg_IV$b[3], 
             1/reg_IV$b[4], 1/reg_IV$b[5])
rts_rownames <- rbind("IVA", "IVB","IVC","IVD","IVE")

reg_IV_df <- data.frame(rts_rownames,rts)


reg_IV_table <- reg_IV_df %>% knitr::kable(
    col.names = c("Regression","Returns to Scale"),
    format.args = list(scientific = F, digits = 4),
    booktabs = T,
    escape = F
  )

reg_IV_table

```



**Are there any noticeable changes in returns to scale from the previous part?**

*We got roughly the same point estimates on returns to scale as the previous part! There is a slight bit of variation which is from the pooled labor and capital price effect. I would imagine we'd get even closer to the previous result if we interacted our industry dummy variable with each of them.*

## Question 7:
**Conduct a statistical test comparing the first model you estimate to the last model you estimated. (Hint: Is one model a restricted version of the other?). Would separate t-test have given you the same results?**

Regression I is the restricted model, Regression IV is unrestricted model. This being, Regression I says that all five industries all have the same slope on output and all have the same intercept, thus placing restrictions.

$F = \frac{(SSR_R - SSR_U)/J}{SSR_U/(n-k)}$

``` {r joint_test}
# Calculate F_stat using SSR approach
ssr_u <- reg_IV$SSR
dof <- reg_IV$dof

ssr_r <- reg_I$SSR
j <- 8 

f_statistic <- ((ssr_r - ssr_u) / j) / (ssr_u / dof)

# Calculate the p-value
p_value <- pf(q = f_statistic, df1 = j, df2 = dof, lower.tail = F)
# Create a data.frame of the f stat. and p-value
f_test <- data.frame(
  f_statistic = f_statistic %>% as.vector(),
  p_value = p_value %>% as.vector())
f_test

F_test(df, "TCscaled", c("lQ_A", "lQ_B", "lQ_C", "lQ_D", "lQ_E", "PLscaled","PKscaled", "g1", "g2", "g3", "g4"))

```
*As you can see, we got an incredibly low p_value between the first and last model, menaing the differentiated slope on output and intercept coefficients are joint, statistically significant. This SSR approach is different than just doing an F-Test on the last regression because it is saying, are all the variables (including the pooled price on labor and capital) jointly, statistically significant from just the mean of the scaled log of total cost. I don't even want to begin thinking about running a myriad of t-test on the 8 individual restrictions of our first model. Theory tells us we are likely to get different results because the F-test correctly ajusts the joint confidence intervals while seperate t-test would be a ridgid overlapping of confidence intervals that may(not) correctly approximate the F-test.*

## Question 8:
**To see whether returns to scale declined with output, Nerlove tested a nonlinear specification by including $ln(y)^2$ as a regressor. Conduct a statistical test you feel is appropriate to test this hypothesis.**

It follows that returns to scale (r)  $= \frac{1}{\alpha + \beta ln(y)}$, where $\alpha$ is the cofficient on ln(y) and $\beta$ is the coefficient on $ln(y)^2$ in the below regression.

``` {r nonlinearspec}

df %<>% mutate(Qlog_sq = (Qlog)^2)

reg_nl <- ols(data = df, y_data = "TCscaled",
             X_data = c("Qlog","Qlog_sq", "PLscaled","PKscaled"),
             intercept = T, H0 = 0, alpha = 0.05)

reg_nl$ttest
```

We're going to save these results and first plot our calculated returns to scale variable against log output to see if there is a trend.

```{r}
df %<>% mutate(rts_nl = 1/(reg_nl$b[2] + reg_nl$b[3]*df$Qlog))

ggplot(df, aes(x=Qlog, y=rts_nl)) + 
  geom_point() + 
  labs(title="Decreasing Returns to Scale?", x="Log Output", y="Calculated RTS")
```

It would seem that our Returns to Scale Decreases as output increases. Whether this is statisically significant is the question. We'll run a regression with these two variables and our pooled labor and capital price in a t-test. Dut to the non-linear decline of returns to scale, we'll also include the squared log output in the regression.

```{r}
reg_nl2 <- ols(data = df, y_data = "rts_nl",
             X_data = c("Qlog","Qlog_sq","PLscaled","PKscaled"),
             intercept = T, H0 = 0, alpha = 0.05)

reg_nl2$ttest
```

Here, it would seem that for every one percent increase of output for firms, we see a `r reg_nl2$b[2]/100` decrease in the firms returns to scale. The results is statistically significant, though, we did not take the robust variance of the original paper throughout, so I don't know how much we can rely on that.
